{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "166330a2",
   "metadata": {},
   "source": [
    "- How do you avoid overfitting your model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec3aa7f",
   "metadata": {},
   "source": [
    "there are three main method to avoid overfitting:\n",
    "\n",
    "1. keep the model simple - take fewer variables into account,thereby removing some of the noise in the training data.\n",
    "\n",
    "2. Use cross-validation techniques, such as k folds cross-validation\n",
    "\n",
    "3. use regularization techniques such as Lasso that penalize certain model parameters if they're likely to cause overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ea804b",
   "metadata": {},
   "source": [
    "- What is the difference between univariate, bivariate, and multivariate analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c8caa4",
   "metadata": {},
   "source": [
    "univariate - contains only one variable. for example height of student, we could analyze all heights and draw conclusions using mean, median, mode, dispersion or range, minimum, maximum for only heights variable.\n",
    "\n",
    "bivariate - data involves two different variables.The analysis of this type of data deals with causes and relationships and analysis is done to determine the relationship between the two variables. for example: tempetere and ice creame the hotter the tempeture the better the seles.\n",
    "\n",
    "multivariate - data involves three or more variables, it is categorized under multivariate. it is similar to a bivariate but contains more than one dependent variable. fro example house price prediction based on number of rooms, proximity to good schools, and stores. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4af897d",
   "metadata": {},
   "source": [
    "- what is tokenization?- what are some issues that arise with it?\n",
    "\n",
    "Tokenization is the process of transformning a string or document into smaller chunks. breaking out words or sentences,seperating punctuation,seperating all hashtags in tweets.\n",
    "\n",
    "- what is hyphenation?\n",
    "\n",
    "In English, hyphenation is used for various purposes ranging from splitting up vowels in words (co-education) to joining nouns as names (Hewlett-Packard) to a copyediting device to show word grouping (the hold-him-back-and-drag-him-away maneuver). It is easy to feel that the first example should be regarded as one token (and is indeed more commonly written as just coeducation), the last should be separated into words, and that the middle case is unclear. Handling hyphens automatically can thus be complex: it can either be done as a classification problem, or more commonly by some heuristic rules, such as allowing short hyphenated prefixes on words, but not longer hyphenated forms.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ed690a",
   "metadata": {},
   "source": [
    "# 1.Take the result of the following line of code (but use whatever available text you want) and write a function to concatenate the data back into sentences, with one readable sentence in each list. sentences = nltk.corpus.gutenberg.sents(\"carroll-alice.txt\")[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5827bcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lorem', 'ipsum', 'dolor', 'sit', 'amet', ',', 'consectetur', 'adipiscing', 'elit', '.', 'Donec', 'vestibulum', 'vitae', 'enim', 'sed', 'hendrerit', '.', 'Class', 'aptent', 'taciti', 'sociosqu', 'ad', 'litora', 'torquent', 'per', 'conubia', 'nostra', ',', 'per', 'inceptos', 'himenaeos', '.', 'Donec', 'sodales', 'orci', 'non', 'sapien', 'malesuada', 'ultricies', '.', 'Sed', 'odio', 'lectus', ',', 'dapibus', 'ut', 'ornare', 'convallis', ',', 'dapibus', 'ac', 'nulla', '.', 'Nullam', 'dapibus', 'mi', 'quis', 'velit', 'imperdiet', ',', 'et', 'tempor', 'ligula', 'imperdiet', '.', 'Donec', 'ultricies', 'nisi', 'sit', 'amet', 'velit', 'dapibus', ',', 'quis', 'tincidunt', 'nisl', 'porta', '.', 'Cras', 'fringilla', 'arcu', 'quis', 'felis', 'egestas', 'ultricies', '.', 'Integer', 'et', 'ligula', 'a', 'risus', 'porta', 'euismod', 'id', 'non', 'sem', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "# https://www.lipsum.com\n",
    "\n",
    "text = '''\n",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit. \n",
    "Donec vestibulum vitae enim sed hendrerit. Class aptent taciti \n",
    "sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos.\n",
    "Donec sodales orci non sapien malesuada ultricies. Sed odio lectus, dapibus\n",
    "ut ornare convallis, dapibus ac nulla. Nullam dapibus mi quis velit imperdiet,\n",
    "et tempor ligula imperdiet. Donec ultricies nisi sit amet velit dapibus, quis \n",
    "tincidunt nisl porta. Cras fringilla arcu quis felis egestas ultricies. Integer\n",
    "et ligula a risus porta euismod id non sem.\n",
    "'''\n",
    "print(word_tokenize(text))\n",
    "\n",
    "#keras has a tokenizer\n",
    "#boundary of words can be complicated, but in english this is not as complex as in other languages\n",
    "#handling symbols can also be hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3003897",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\12674\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c7a71d",
   "metadata": {},
   "source": [
    "# Gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4693c719",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\12674\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\gutenberg.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a3c118c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "#nltk.download('gutenberg')\n",
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a862fb7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', 'Alice', \"'\", 's', 'Adventures', 'in', ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiw = nltk.corpus.gutenberg.words('carroll-alice.txt')\n",
    "aiw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8c28d2",
   "metadata": {},
   "source": [
    " # Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54207602",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\12674\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f5355ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stop words are common words that have low information value\n",
    "#generally, we want to get rid of these stop words\n",
    "#nltk.download('stopwords')\n",
    "sw = set(nltk.corpus.stopwords.words('english'))\n",
    "sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86aa6c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['[', 'Alice', \"'\", 's', 'Adventures', 'in', 'Wonderland', 'by', 'Lewis', 'Carroll', '1865', ']'], ['CHAPTER', 'I', '.'], ['Down', 'the', 'Rabbit', '-', 'Hole'], ['Alice', 'was', 'beginning', 'to', 'get', 'very', 'tired', 'of', 'sitting', 'by', 'her', 'sister', 'on', 'the', 'bank', ',', 'and', 'of', 'having', 'nothing', 'to', 'do', ':', 'once', 'or', 'twice', 'she', 'had', 'peeped', 'into', 'the', 'book', 'her', 'sister', 'was', 'reading', ',', 'but', 'it', 'had', 'no', 'pictures', 'or', 'conversations', 'in', 'it', ',', \"'\", 'and', 'what', 'is', 'the', 'use', 'of', 'a', 'book', \",'\", 'thought', 'Alice', \"'\", 'without', 'pictures', 'or', 'conversation', \"?'\"], ['So', 'she', 'was', 'considering', 'in', 'her', 'own', 'mind', '(', 'as', 'well', 'as', 'she', 'could', ',', 'for', 'the', 'hot', 'day', 'made', 'her', 'feel', 'very', 'sleepy', 'and', 'stupid', '),', 'whether', 'the', 'pleasure', 'of', 'making', 'a', 'daisy', '-', 'chain', 'would', 'be', 'worth', 'the', 'trouble', 'of', 'getting', 'up', 'and', 'picking', 'the', 'daisies', ',', 'when', 'suddenly', 'a', 'White', 'Rabbit', 'with', 'pink', 'eyes', 'ran', 'close', 'by', 'her', '.'], ['There', 'was', 'nothing', 'so', 'VERY', 'remarkable', 'in', 'that', ';', 'nor', 'did', 'Alice', 'think', 'it', 'so', 'VERY', 'much', 'out', 'of', 'the', 'way', 'to', 'hear', 'the', 'Rabbit', 'say', 'to', 'itself', ',', \"'\", 'Oh', 'dear', '!'], ['Oh', 'dear', '!'], ['I', 'shall', 'be', 'late', \"!'\"], ['(', 'when', 'she', 'thought', 'it', 'over', 'afterwards', ',', 'it', 'occurred', 'to', 'her', 'that', 'she', 'ought', 'to', 'have', 'wondered', 'at', 'this', ',', 'but', 'at', 'the', 'time', 'it', 'all', 'seemed', 'quite', 'natural', ');', 'but', 'when', 'the', 'Rabbit', 'actually', 'TOOK', 'A', 'WATCH', 'OUT', 'OF', 'ITS', 'WAISTCOAT', '-', 'POCKET', ',', 'and', 'looked', 'at', 'it', ',', 'and', 'then', 'hurried', 'on', ',', 'Alice', 'started', 'to', 'her', 'feet', ',', 'for', 'it', 'flashed', 'across', 'her', 'mind', 'that', 'she', 'had', 'never', 'before', 'seen', 'a', 'rabbit', 'with', 'either', 'a', 'waistcoat', '-', 'pocket', ',', 'or', 'a', 'watch', 'to', 'take', 'out', 'of', 'it', ',', 'and', 'burning', 'with', 'curiosity', ',', 'she', 'ran', 'across', 'the', 'field', 'after', 'it', ',', 'and', 'fortunately', 'was', 'just', 'in', 'time', 'to', 'see', 'it', 'pop', 'down', 'a', 'large', 'rabbit', '-', 'hole', 'under', 'the', 'hedge', '.'], ['In', 'another', 'moment', 'down', 'went', 'Alice', 'after', 'it', ',', 'never', 'once', 'considering', 'how', 'in', 'the', 'world', 'she', 'was', 'to', 'get', 'out', 'again', '.']]\n"
     ]
    }
   ],
   "source": [
    "#nltk.download('punkt')\n",
    "#take corpus and break it up into sentences\n",
    "text_sentences = nltk.corpus.gutenberg.sents('carroll-alice.txt')[:10]\n",
    "print(text_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dda80ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'Alice', \"'\", 'Adventures', 'Wonderland', 'Lewis', 'Carroll', '1865', ']']\n",
      "['CHAPTER', '.']\n",
      "['Rabbit', '-', 'Hole']\n",
      "['Alice', 'beginning', 'get', 'tired', 'sitting', 'sister', 'bank', ',', 'nothing', ':', 'twice', 'peeped', 'book', 'sister', 'reading', ',', 'pictures', 'conversations', ',', \"'\", 'use', 'book', \",'\", 'thought', 'Alice', \"'\", 'without', 'pictures', 'conversation', \"?'\"]\n",
      "['considering', 'mind', '(', 'well', 'could', ',', 'hot', 'day', 'made', 'feel', 'sleepy', 'stupid', '),', 'whether', 'pleasure', 'making', 'daisy', '-', 'chain', 'would', 'worth', 'trouble', 'getting', 'picking', 'daisies', ',', 'suddenly', 'White', 'Rabbit', 'pink', 'eyes', 'ran', 'close', '.']\n",
      "['nothing', 'remarkable', ';', 'Alice', 'think', 'much', 'way', 'hear', 'Rabbit', 'say', ',', \"'\", 'Oh', 'dear', '!']\n",
      "['Oh', 'dear', '!']\n",
      "['shall', 'late', \"!'\"]\n",
      "['(', 'thought', 'afterwards', ',', 'occurred', 'ought', 'wondered', ',', 'time', 'seemed', 'quite', 'natural', ');', 'Rabbit', 'actually', 'TOOK', 'WATCH', 'WAISTCOAT', '-', 'POCKET', ',', 'looked', ',', 'hurried', ',', 'Alice', 'started', 'feet', ',', 'flashed', 'across', 'mind', 'never', 'seen', 'rabbit', 'either', 'waistcoat', '-', 'pocket', ',', 'watch', 'take', ',', 'burning', 'curiosity', ',', 'ran', 'across', 'field', ',', 'fortunately', 'time', 'see', 'pop', 'large', 'rabbit', '-', 'hole', 'hedge', '.']\n",
      "['another', 'moment', 'went', 'Alice', ',', 'never', 'considering', 'world', 'get', '.']\n"
     ]
    }
   ],
   "source": [
    "#stop words are all lowercase. we want to do this too\n",
    "for sentence in text_sentences:\n",
    "    #but we are still preserving the original cases of the words\n",
    "    filtered_list = [w for w in sentence if w.lower() not in sw]\n",
    "    print(filtered_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62a659c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alice', 'Adventures', 'Wonderland', 'Lewis', 'Carroll', '1865']\n",
      "['CHAPTER']\n",
      "['Rabbit', 'Hole']\n",
      "['Alice', 'beginning', 'get', 'tired', 'sitting', 'sister', 'bank', 'nothing', 'twice', 'peeped', 'book', 'sister', 'reading', 'pictures', 'conversations', 'use', 'book', 'thought', 'Alice', 'without', 'pictures', 'conversation']\n",
      "['considering', 'mind', 'well', 'could', 'hot', 'day', 'made', 'feel', 'sleepy', 'stupid', 'whether', 'pleasure', 'making', 'daisy', 'chain', 'would', 'worth', 'trouble', 'getting', 'picking', 'daisies', 'suddenly', 'White', 'Rabbit', 'pink', 'eyes', 'ran', 'close']\n",
      "['nothing', 'remarkable', 'Alice', 'think', 'much', 'way', 'hear', 'Rabbit', 'say', 'Oh', 'dear']\n",
      "['Oh', 'dear']\n",
      "['shall', 'late']\n",
      "['thought', 'afterwards', 'occurred', 'ought', 'wondered', 'time', 'seemed', 'quite', 'natural', 'Rabbit', 'actually', 'TOOK', 'WATCH', 'WAISTCOAT', 'POCKET', 'looked', 'hurried', 'Alice', 'started', 'feet', 'flashed', 'across', 'mind', 'never', 'seen', 'rabbit', 'either', 'waistcoat', 'pocket', 'watch', 'take', 'burning', 'curiosity', 'ran', 'across', 'field', 'fortunately', 'time', 'see', 'pop', 'large', 'rabbit', 'hole', 'hedge']\n",
      "['another', 'moment', 'went', 'Alice', 'never', 'considering', 'world', 'get']\n"
     ]
    }
   ],
   "source": [
    "# take one or two characters that should be eliminated, and write a list comprehension to remove them\n",
    "for sentence in text_sentences:\n",
    "    filtered_list = [w for w in sentence if w.lower() not in sw]\n",
    "    new_filtered_list = [w for w in filtered_list if w.isalnum()]\n",
    "    print(new_filtered_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1933e656",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "735712a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wander'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stemming - finding root words\n",
    "# overstemming - when words are over truncated - car vs care in caring. So, car would be overstemming of caring.\n",
    "# understemming - false negative, so if we convert alumnus to alumnu \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(language='english')\n",
    "word = 'wander'\n",
    "stemmer.stem(word)\n",
    "# fun fact: Google adopted word stemming in 2003. Before this, searching words like \"fish\"\n",
    "# would not have given results for \"fishing\" or \"fishes\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dcdfdf",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4be4a118",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\12674\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c89d19c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\12674\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\omw-1.4.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7f9ac62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fishing\n"
     ]
    }
   ],
   "source": [
    "# lemmatization - finding the form of a word thats related in the dictionary\n",
    "# the process for calculated lemmas is more complex than stemming\n",
    "# lemmatization considers the context AND converts the word to \"meaningful base form\" (a lemma)\n",
    "# a word can have multiple lemmas\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "word = 'fishing'\n",
    "print(lemmatizer.lemmatize(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88065e6b",
   "metadata": {},
   "source": [
    " # Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3355a366",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\12674\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9864b31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "#nltk.download('vader_lexicon')\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "856b5eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "Etymology and naming\n",
    "The origin of the English word 'cat', Old English catt, is thought to be the Late Latin word cattus, which was first used at the beginning of the 6th century.[20] It was suggested that the word 'cattus' is derived from an Egyptian precursor of Coptic ϣⲁⲩ šau, \"tomcat\", or its feminine form suffixed with -t.[21] The Late Latin word may be derived from another Afro-Asiatic[22] or\n",
    "Nilo-Saharan language. The Nubian word kaddîska \"wildcat\" and Nobiin kadīs are possible sources or cognates.[23] \n",
    "The Nubian word may be a loan from Arabic قَطّ‎ qaṭṭ ~ قِطّ qiṭṭ. It is \"equally likely that the forms might derive from an\n",
    "ancient Germanic word, imported into Latin and thence to Greek and to Syriac and Arabic\".[24] The word may be derived \n",
    "from Germanic and Northern European languages, and ultimately be borrowed from Uralic, cf. Northern Sami gáđfi, \"female stoat\",\n",
    "and Hungarian hölgy, \"stoat\"; from Proto-Uralic *käďwä, \"female (of a furred animal)\".[25]\n",
    "The English puss, extended as pussy and pussycat, is attested from the 16th century and may have been introduced from Dutch\n",
    "poes or from Low German puuskatte, related to Swedish kattepus, or Norwegian pus, pusekatt. Similar forms exist in Lithuanian\n",
    "puižė and Irish puisín or puiscín. The etymology of this word is unknown, but it may have simply arisen from a sound used to\n",
    "attract a cat.[26][27]\n",
    "A male cat is called a tom or tomcat[28] (or a gib,[29] if neutered). An unspayed female is called a queen,[30] especially\n",
    "in a cat-breeding context. A juvenile cat is referred to as a kitten. In Early Modern English, the word kitten was\n",
    "interchangeable with the now-obsolete word catling.[31] A group of cats can be referred to as a clowder or a glaring.[32]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df23d27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.006, 'neu': 0.983, 'pos': 0.012, 'compound': 0.4019}\n"
     ]
    }
   ],
   "source": [
    "sentiments = []\n",
    "sentiment = analyzer.polarity_scores(text)\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ecf0b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': '\\nEtymology and naming\\nThe origin of the English word \\'cat\\', Old English catt, is thought to be the Late Latin word cattus, which was first used at the beginning of the 6th century.[20] It was suggested that the word \\'cattus\\' is derived from an Egyptian precursor of Coptic ϣⲁⲩ šau, \"tomcat\", or its feminine form suffixed with -t.[21] The Late Latin word may be derived from another Afro-Asiatic[22] or\\nNilo-Saharan language. The Nubian word kaddîska \"wildcat\" and Nobiin kadīs are possible sources or cognates.[23] \\nThe Nubian word may be a loan from Arabic قَطّ\\u200e qaṭṭ ~ قِطّ qiṭṭ. It is \"equally likely that the forms might derive from an\\nancient Germanic word, imported into Latin and thence to Greek and to Syriac and Arabic\".[24] The word may be derived \\nfrom Germanic and Northern European languages, and ultimately be borrowed from Uralic, cf. Northern Sami gáđfi, \"female stoat\",\\nand Hungarian hölgy, \"stoat\"; from Proto-Uralic *käďwä, \"female (of a furred animal)\".[25]\\nThe English puss, extended as pussy and pussycat, is attested from the 16th century and may have been introduced from Dutch\\npoes or from Low German puuskatte, related to Swedish kattepus, or Norwegian pus, pusekatt. Similar forms exist in Lithuanian\\npuižė and Irish puisín or puiscín. The etymology of this word is unknown, but it may have simply arisen from a sound used to\\nattract a cat.[26][27]\\nA male cat is called a tom or tomcat[28] (or a gib,[29] if neutered). An unspayed female is called a queen,[30] especially\\nin a cat-breeding context. A juvenile cat is referred to as a kitten. In Early Modern English, the word kitten was\\ninterchangeable with the now-obsolete word catling.[31] A group of cats can be referred to as a clowder or a glaring.[32]\\n',\n",
       "  'compound': 0.4019,\n",
       "  'positive': 0.012,\n",
       "  'negative': 0.006,\n",
       "  'neutral': 0.983}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compound = sentiment[\"compound\"]\n",
    "pos = sentiment['pos']\n",
    "neu = sentiment['neu']\n",
    "neg = sentiment['neg']\n",
    "\n",
    "sentiments.append({\n",
    "            \"text\":text,\n",
    "            \"compound\":compound,\n",
    "            \"positive\":pos,\n",
    "            \"negative\":neg,\n",
    "            \"neutral\":neu\n",
    "})\n",
    "sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00c772e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "sentences = nltk.corpus.gutenberg.sents(\"carroll-alice.txt\")[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "742062cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['[', 'Alice', \"'\", 's', 'Adventures', 'in', 'Wonderland', 'by', 'Lewis', 'Carroll', '1865', ']'], ['CHAPTER', 'I', '.'], ['Down', 'the', 'Rabbit', '-', 'Hole'], ['Alice', 'was', 'beginning', 'to', 'get', 'very', 'tired', 'of', 'sitting', 'by', 'her', 'sister', 'on', 'the', 'bank', ',', 'and', 'of', 'having', 'nothing', 'to', 'do', ':', 'once', 'or', 'twice', 'she', 'had', 'peeped', 'into', 'the', 'book', 'her', 'sister', 'was', 'reading', ',', 'but', 'it', 'had', 'no', 'pictures', 'or', 'conversations', 'in', 'it', ',', \"'\", 'and', 'what', 'is', 'the', 'use', 'of', 'a', 'book', \",'\", 'thought', 'Alice', \"'\", 'without', 'pictures', 'or', 'conversation', \"?'\"], ['So', 'she', 'was', 'considering', 'in', 'her', 'own', 'mind', '(', 'as', 'well', 'as', 'she', 'could', ',', 'for', 'the', 'hot', 'day', 'made', 'her', 'feel', 'very', 'sleepy', 'and', 'stupid', '),', 'whether', 'the', 'pleasure', 'of', 'making', 'a', 'daisy', '-', 'chain', 'would', 'be', 'worth', 'the', 'trouble', 'of', 'getting', 'up', 'and', 'picking', 'the', 'daisies', ',', 'when', 'suddenly', 'a', 'White', 'Rabbit', 'with', 'pink', 'eyes', 'ran', 'close', 'by', 'her', '.'], ['There', 'was', 'nothing', 'so', 'VERY', 'remarkable', 'in', 'that', ';', 'nor', 'did', 'Alice', 'think', 'it', 'so', 'VERY', 'much', 'out', 'of', 'the', 'way', 'to', 'hear', 'the', 'Rabbit', 'say', 'to', 'itself', ',', \"'\", 'Oh', 'dear', '!'], ['Oh', 'dear', '!'], ['I', 'shall', 'be', 'late', \"!'\"], ['(', 'when', 'she', 'thought', 'it', 'over', 'afterwards', ',', 'it', 'occurred', 'to', 'her', 'that', 'she', 'ought', 'to', 'have', 'wondered', 'at', 'this', ',', 'but', 'at', 'the', 'time', 'it', 'all', 'seemed', 'quite', 'natural', ');', 'but', 'when', 'the', 'Rabbit', 'actually', 'TOOK', 'A', 'WATCH', 'OUT', 'OF', 'ITS', 'WAISTCOAT', '-', 'POCKET', ',', 'and', 'looked', 'at', 'it', ',', 'and', 'then', 'hurried', 'on', ',', 'Alice', 'started', 'to', 'her', 'feet', ',', 'for', 'it', 'flashed', 'across', 'her', 'mind', 'that', 'she', 'had', 'never', 'before', 'seen', 'a', 'rabbit', 'with', 'either', 'a', 'waistcoat', '-', 'pocket', ',', 'or', 'a', 'watch', 'to', 'take', 'out', 'of', 'it', ',', 'and', 'burning', 'with', 'curiosity', ',', 'she', 'ran', 'across', 'the', 'field', 'after', 'it', ',', 'and', 'fortunately', 'was', 'just', 'in', 'time', 'to', 'see', 'it', 'pop', 'down', 'a', 'large', 'rabbit', '-', 'hole', 'under', 'the', 'hedge', '.'], ['In', 'another', 'moment', 'down', 'went', 'Alice', 'after', 'it', ',', 'never', 'once', 'considering', 'how', 'in', 'the', 'world', 'she', 'was', 'to', 'get', 'out', 'again', '.']]\n"
     ]
    }
   ],
   "source": [
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "449beec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_together(input_sent):\n",
    "    '''This function puts the sentences back together'''\n",
    "    str1 = \" \"\n",
    "    out = []\n",
    "    # the join command puts the strings together but it needs to be in a list so it was appended to the output.\n",
    "    out.append(str1.join(input_sent))\n",
    "    print(out)\n",
    "    return\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e1179e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"[ Alice ' s Adventures in Wonderland by Lewis Carroll 1865 ]\"]\n",
      "['CHAPTER I .']\n",
      "['Down the Rabbit - Hole']\n",
      "[\"Alice was beginning to get very tired of sitting by her sister on the bank , and of having nothing to do : once or twice she had peeped into the book her sister was reading , but it had no pictures or conversations in it , ' and what is the use of a book ,' thought Alice ' without pictures or conversation ?'\"]\n",
      "['So she was considering in her own mind ( as well as she could , for the hot day made her feel very sleepy and stupid ), whether the pleasure of making a daisy - chain would be worth the trouble of getting up and picking the daisies , when suddenly a White Rabbit with pink eyes ran close by her .']\n",
      "[\"There was nothing so VERY remarkable in that ; nor did Alice think it so VERY much out of the way to hear the Rabbit say to itself , ' Oh dear !\"]\n",
      "['Oh dear !']\n",
      "[\"I shall be late !'\"]\n",
      "['( when she thought it over afterwards , it occurred to her that she ought to have wondered at this , but at the time it all seemed quite natural ); but when the Rabbit actually TOOK A WATCH OUT OF ITS WAISTCOAT - POCKET , and looked at it , and then hurried on , Alice started to her feet , for it flashed across her mind that she had never before seen a rabbit with either a waistcoat - pocket , or a watch to take out of it , and burning with curiosity , she ran across the field after it , and fortunately was just in time to see it pop down a large rabbit - hole under the hedge .']\n",
      "['In another moment down went Alice after it , never once considering how in the world she was to get out again .']\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(sentences)):\n",
    "    put_together(sentences[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46677e6",
   "metadata": {},
   "source": [
    "2.Create a function that accepts a list of values. Filter out all values that are numeric and\n",
    "return the new list.\n",
    "Input:\n",
    "[1,2,'a','b',7.6]\n",
    "output:\n",
    "[‘a’,’b’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9ceb6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_list(list_in):\n",
    "    \"\"\"This function accepts a list of values and returns the non-numeric characters as a list\"\"\"\n",
    "    new_values_list = []\n",
    "    for string in list_in:\n",
    "        try:\n",
    "            if string.isalpha():\n",
    "                new_values_list.append(string)\n",
    "        except:\n",
    "            pass\n",
    "        print(new_values_list)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a5e011a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "['a']\n",
      "['a', 'b']\n",
      "['a', 'b']\n"
     ]
    }
   ],
   "source": [
    "value_list([1,2,'a','b',7.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5ff6f026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def numbers(s):\n",
    "    \n",
    "    return[(match) for match in re.findall(r\"[a-z]\",s)]\n",
    "        \n",
    "numbers(\"1,2,'a','b',7.6\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e04659",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
